{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280},{"sourceId":2882784,"sourceType":"datasetVersion","datasetId":1748489},{"sourceId":11339277,"sourceType":"datasetVersion","datasetId":7093867}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n# Clear any existing GPU settings\ntf.keras.backend.clear_session()\n\n# Set TensorFlow to run on GPU\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Allow memory growth to prevent OOM (Out-of-Memory) errors\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"GPU is set up successfully!\")\n    except RuntimeError as e:\n        print(f\"GPU Setup Error: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nimport shutil","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset paths\ndataset1_path = \"/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets\"\ndataset2_path = \"/kaggle/input/iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset\"\ncombined_dataset_path = \"/kaggle/working/Combined_Lung_Dataset\"\n\n# Mapping folders to 3-class structure\ndatasets = {\n    \"lung_n\": \"Normal\",\n    \"Normal cases\": \"Normal\",\n    \"Bengin cases\": \"Benign\",\n    \"lung_aca\": \"Malignant\",\n    \"lung_scc\": \"Malignant\",\n    \"Malignant cases\": \"Malignant\",\n}\n\n# Make sure combined class folders exist\nfor category in set(datasets.values()):\n    os.makedirs(os.path.join(combined_dataset_path, category), exist_ok=True)\n\n# Function to copy & rename images with prefix\ndef copy_images(source_folder, target_folder, prefix):\n    if os.path.exists(source_folder):\n        for file in os.listdir(source_folder):\n            if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n                src_path = os.path.join(source_folder, file)\n                new_filename = f\"{prefix}_{file}\"\n                dst_path = os.path.join(target_folder, new_filename)\n                shutil.copy(src_path, dst_path)\n\n# Copy dataset 1 (H&E histology) ‚Üí add \"histo_\" prefix\nfor folder, category in datasets.items():\n    source_folder = os.path.join(dataset1_path, folder)\n    target_folder = os.path.join(combined_dataset_path, category)\n    copy_images(source_folder, target_folder, prefix=\"histo\")\n\n# Copy dataset 2 (CT scans) ‚Üí add \"ct_\" prefix\nfor folder, category in datasets.items():\n    source_folder = os.path.join(dataset2_path, folder)\n    target_folder = os.path.join(combined_dataset_path, category)\n    copy_images(source_folder, target_folder, prefix=\"ct\")\n\n# Cleanup: remove any empty folders\nfor category in set(datasets.values()):\n    target_folder = os.path.join(combined_dataset_path, category)\n    if len(os.listdir(target_folder)) == 0:\n        print(f\"Removing empty folder: {target_folder}\")\n        shutil.rmtree(target_folder)\n\nprint(\"‚úÖ Dataset successfully merged into 3 classes: Normal, Benign, Malignant with histo/ct prefixes!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# === Paths ===\nreal_benign = \"/kaggle/working/Combined_Lung_Dataset/Benign\"\nsynthetic_benign = \"/kaggle/input/gan-images-iq-othnccd-benign\"\ntarget_non_malignant = \"/kaggle/working/Combined_Lung_Dataset/Non-Malignant\"\n\n# Create target folder\nos.makedirs(target_non_malignant, exist_ok=True)\n\n# === Copy Real Benign Images (prefix: real_) ===\nfor filename in os.listdir(real_benign):\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n        src = os.path.join(real_benign, filename)\n        dst = os.path.join(target_non_malignant, f\"real_{filename}\")\n        shutil.copyfile(src, dst)\n\n# === Copy Synthetic Benign Images (prefix: ct_synthetic_) ===\nfor filename in os.listdir(synthetic_benign):\n    if filename.lower().endswith('.png'):  # All synthetic are .png\n        src = os.path.join(synthetic_benign, filename)\n        dst = os.path.join(target_non_malignant, f\"ct_synthetic_{filename}\")\n        shutil.copyfile(src, dst)\n\nprint(f\"‚úÖ Combined Real + Synthetic Benign images into: {target_non_malignant}\")\nprint(f\"üßæ Total: {len(os.listdir(target_non_malignant))} images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Define paths ===\nroot_dataset = \"/kaggle/working/Combined_Lung_Dataset\"\nnormal_dir = os.path.join(root_dataset, \"Normal\")\nbenign_combined_dir = os.path.join(root_dataset, \"Non-Malignant\")  # this contains real + synthetic Benign\nmalignant_dir = os.path.join(root_dataset, \"Malignant\")\n\n# Final binary class folder\nfinal_dataset = \"/kaggle/working/Final_Binary_Dataset\"\nfinal_non_malignant = os.path.join(final_dataset, \"Non-Malignant\")\nfinal_malignant = os.path.join(final_dataset, \"Malignant\")\n\n# === Create directories ===\nos.makedirs(final_non_malignant, exist_ok=True)\nos.makedirs(final_malignant, exist_ok=True)\n\n# === Copy Normal images to Non-Malignant ===\nfor file in os.listdir(normal_dir):\n    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n        src = os.path.join(normal_dir, file)\n        dst = os.path.join(final_non_malignant, f\"normal_{file}\")\n        shutil.copyfile(src, dst)\n\n# === Copy Benign (real + synthetic) to Non-Malignant ===\nfor file in os.listdir(benign_combined_dir):\n    if file.lower().endswith('.png') or file.lower().endswith(('.jpg', '.jpeg')):\n        src = os.path.join(benign_combined_dir, file)\n        dst = os.path.join(final_non_malignant, file)\n        shutil.copyfile(src, dst)\n\n# === Copy Malignant images ===\nfor file in os.listdir(malignant_dir):\n    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n        src = os.path.join(malignant_dir, file)\n        dst = os.path.join(final_malignant, file)\n        shutil.copyfile(src, dst)\n\nprint(\"‚úÖ Final Binary Dataset structure created at /kaggle/working/Final_Binary_Dataset\")\nprint(f\"üìÅ Non-Malignant: {len(os.listdir(final_non_malignant))} images\")\nprint(f\"üìÅ Malignant: {len(os.listdir(final_malignant))} images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndata_dir = \"/kaggle/working/Final_Binary_Dataset\"\nnp.random.seed(42)\n\nimage_paths = []\nlabels = []\nsynthetic_paths = []\nsynthetic_labels = []\nlabel_dict = {}\n\n# === Load image paths and separate synthetic ===\nfor idx, class_name in enumerate(sorted(os.listdir(data_dir))):\n    class_dir = os.path.join(data_dir, class_name)\n    if os.path.isdir(class_dir):\n        label_dict[class_name] = idx\n        for file in os.listdir(class_dir):\n            full_path = os.path.join(class_dir, file)\n            if class_name == \"Non-Malignant\" and file.startswith(\"synthetic_\"):\n                synthetic_paths.append(full_path)\n                synthetic_labels.append(idx)\n            else:\n                image_paths.append(full_path)\n                labels.append(idx)\n\nimage_paths = np.array(image_paths)\nlabels = np.array(labels)\nsynthetic_paths = np.array(synthetic_paths)\nsynthetic_labels = np.array(synthetic_labels)\n\n# === Split real data into 70% train, 20% val, 10% test ===\nX_temp, X_test, y_temp, y_test = train_test_split(\n    image_paths, labels, test_size=0.1, stratify=labels, random_state=42)\n\nX_train_real, X_val, y_train_real, y_val = train_test_split(\n    X_temp, y_temp, test_size=2/9, stratify=y_temp, random_state=42)  # 2/9 of 90% ‚Üí ~20%\n\n# === Add synthetic data to training set only ===\nX_train = np.concatenate((X_train_real, synthetic_paths))\ny_train = np.concatenate((y_train_real, synthetic_labels))\n\n# === Done ===\nprint(\"‚úÖ 70/20/10 Split complete (synthetic used only in training).\")\nprint(f\"üì¶ Training Set: {len(X_train)} images (with synthetic)\")\nprint(f\"üß™ Validation Set: {len(X_val)} images (real only)\")\nprint(f\"üß´ Test Set: {len(X_test)} images (real only)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\ndef print_distribution(y, name=\"\"):\n    counts = Counter(y)\n    total = len(y)\n    print(f\"üìä {name} Set Distribution:\")\n    for label, count in sorted(counts.items()):\n        percentage = (count / total) * 100\n        print(f\"  Class {label} ‚Üí {count} samples ({percentage:.2f}%)\")\n    print(f\"  Total: {total} images\\n\")\n\n# Example:\nprint_distribution(y_train, \"Train\")\nprint_distribution(y_val, \"Validation\")\nprint_distribution(y_test, \"Test\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nimage_size = (256, 256)\nmean = tf.convert_to_tensor([0.485, 0.456, 0.406], dtype=tf.float32)\nstd = tf.convert_to_tensor([0.229, 0.224, 0.225], dtype=tf.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function\ndef augment_image(image, label, filename):\n    # Apply base spatial transforms to all images\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n\n    if tf.random.uniform([]) > 0.7:\n        k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n        image = tf.image.rot90(image, k)\n\n    # === Conditional Augmentations ===\n    # For histopathology images (H&E)\n    if tf.strings.regex_full_match(filename, \".*histo.*|.*real.*\"):\n        if tf.random.uniform([]) > 0.7:\n            image = tf.image.random_brightness(image, max_delta=0.08)\n        if tf.random.uniform([]) > 0.7:\n            image = tf.image.random_contrast(image, 0.9, 1.1)\n        if tf.random.uniform([]) > 0.7:\n            image = tf.image.random_saturation(image, 0.9, 1.1)\n        if tf.random.uniform([]) > 0.9:\n            image = tf.image.random_jpeg_quality(image, 80, 100)\n        if tf.random.uniform([]) > 0.7:\n            image = tf.image.central_crop(image, 0.9)\n            image = tf.image.resize(image, [256, 256])\n        if tf.random.uniform([]) > 0.7:\n            noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.01)\n            image = tf.clip_by_value(image + noise, 0.0, 1.0)\n\n    # For CT/synthetic images\n    elif tf.strings.regex_full_match(filename, \".*ct.*|.*synthetic.*\"):\n        # Less aggressive augmentations for CT\n        if tf.random.uniform([]) > 0.8:\n            image = tf.image.central_crop(image, 0.95)\n            image = tf.image.resize(image, [256, 256])\n        if tf.random.uniform([]) > 0.8:\n            # Slight noise for CT images\n            noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.002)\n            image = tf.clip_by_value(image + noise, 0.0, 1.0)\n        if tf.random.uniform([]) > 0.2:  # Small probability for brightness change for CT\n            image = tf.image.random_brightness(image, max_delta=0.02)  # Small brightness for CT scans\n\n    return image, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================= Preprocessing Function ================= #\ndef load_and_preprocess_image(image_path, label, augment=False):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, image_size)\n    print(\"Before normalization:\", tf.reduce_min(img), tf.reduce_max(img))\n    img = img / 255.0  # Normalize pixel values\n    print(\"After division by 255:\", tf.reduce_min(img), tf.reduce_max(img))\n    # Apply augmentation only if augment=True\n    if augment:\n        img, label = augment_image(img, label, filename)\n    print(\"After mean/std normalization:\", tf.reduce_min(img), tf.reduce_max(img))\n    img = (img - mean) / std  # Apply mean-std normalization\n    img = tf.cast(img, tf.float32)\n    return img, label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================= Dataset Creation ================= #\ndef create_dataset(image_paths, labels, batch_size=32, shuffle=True, augment=False):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n    dataset = dataset.map(lambda x, y: load_and_preprocess_image(x, y, augment), num_parallel_calls=tf.data.AUTOTUNE)\n    if shuffle:\n        dataset = dataset.shuffle(len(image_paths))\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Create datasets\ntrain_dataset = create_dataset(X_train, y_train, augment=True)  # Augmentation only in training\nval_dataset = create_dataset(X_val, y_val, shuffle=False)\ntest_dataset = create_dataset(X_test, y_test, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Take batches and flatten to 50 individual images\nimages = []\nlabels = []\n\n# Collect 50 images\nfor batch_images, batch_labels in train_dataset:\n    for i in range(len(batch_images)):\n        images.append(batch_images[i])\n        labels.append(batch_labels[i])\n        if len(images) == 50:\n            break\n    if len(images) == 50:\n        break\n\n# Plot 50 images in a 10x5 grid\nplt.figure(figsize=(20, 10))  # Adjust size as needed\n\nfor i in range(50):\n    plt.subplot(5, 10, i + 1)\n    plt.imshow(tf.clip_by_value(images[i], 0.0, 1.0).numpy())\n    plt.title(f\"{int(labels[i])}\", fontsize=8)\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.optimizers import SGD, Adam\nimport matplotlib.pyplot as plt\n\n# Function to create a residual block (for ResNet)\ndef residual_block(x, filters, kernel_size=3, stride=1, downsample=False):\n    shortcut = x\n\n    # First convolution layer\n    x = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # Second convolution layer\n    x = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\")(x)  # stride = 1 in second layer\n    x = layers.BatchNormalization()(x)\n\n    # If downsample is True, apply a 1x1 convolution to the shortcut path to match dimensions\n    if downsample:\n        shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding=\"same\")(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    # Add the shortcut to the output\n    x = layers.Add()([x, shortcut])\n    x = layers.ReLU()(x)\n    return x\n\n# ================== Model Builder ==================#\ndef create_resnet150(input_shape=(256, 256, 3), num_classes=1):\n    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False  # Freeze the base model initially\n\n    # Define the input layer\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Initial Conv Layer\n    x = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # Initial max pooling layer\n    x = layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\")(x)\n\n    # ResNet blocks configuration (ResNet150 typically has more layers and blocks)\n    block_configs = [(3, 64, 2), (4, 128, 2), (6, 256, 2), (3, 512, 2)]\n\n    # Add residual blocks\n    for num_blocks, filters, stride in block_configs:\n        for i in range(num_blocks):\n            x = residual_block(x, filters, stride=(stride if i == 0 else 1), downsample=(i == 0))\n\n    # Global Average Pooling layer\n    x = layers.GlobalAveragePooling2D()(x)\n\n    # Fully connected layers\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)  # Dropout added to reduce overfitting\n    final_output = layers.Dense(num_classes, activation='sigmoid')(x)\n    \n    model = models.Model(inputs, final_output)\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),  # Using Adam optimizer for smoother convergence\n        loss='binary_crossentropy',  # Use binary cross entropy for binary classification\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# ================== Learning Rate Scheduler ==================#\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr  # Keep the learning rate constant for the first 10 epochs\n    return lr * 0.8  # Reduce learning rate by 20% after 10 epochs\n\ncallback_lr = LearningRateScheduler(scheduler)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"best_model_resnet150.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n\n# ================== Get the Model ==================#\nmodel = create_resnet150(input_shape=(256, 256, 3))\n\n# ================== Train the Model ==================#\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=20,\n    callbacks=[callback_lr, early_stopping, model_checkpoint],\n    verbose=1\n)\n\n# ================== Evaluation ==================#\ntest_loss, test_acc = model.evaluate(test_dataset)\nprint(f\"Test Accuracy: {test_acc * 100:.2f}%\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n\n# ================== Plot Accuracy & Loss ==================#\nplt.figure(figsize=(10, 6))\n\n# Plot training vs validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.legend()\n\n# Plot training vs validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training vs Validation Loss')\nplt.legend()\n\nplt.show()\n\n# ================== Save Final Model ==================#\nmodel.save('/kaggle/working/resnet150_model.h5') \n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\n# Function to create a residual block (for ResNet)\ndef residual_block(x, filters, kernel_size=3, stride=1, downsample=False):\n    shortcut = x\n\n    # First convolution layer\n    x = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # Second convolution layer\n    x = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\")(x)  # stride = 1 in second layer\n    x = layers.BatchNormalization()(x)\n\n    # If downsample is True, apply a 1x1 convolution to the shortcut path to match dimensions\n    if downsample:\n        shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding=\"same\")(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    # Add the shortcut to the output\n    x = layers.Add()([x, shortcut])\n    x = layers.ReLU()(x)\n    return x\n\n# ================== Model Builder ==================#\ndef create_resnet150(input_shape=(256, 256, 3), num_classes=1):\n    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False  # Freeze the base model initially\n\n    # Define the input layer\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Initial Conv Layer\n    x = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n\n    # Initial max pooling layer\n    x = layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\")(x)\n\n    # ResNet blocks configuration (ResNet150 typically has more layers and blocks)\n    block_configs = [(3, 64, 2), (4, 128, 2), (6, 256, 2), (3, 512, 2)]\n\n    # Add residual blocks\n    for num_blocks, filters, stride in block_configs:\n        for i in range(num_blocks):\n            x = residual_block(x, filters, stride=(stride if i == 0 else 1), downsample=(i == 0))\n\n    # Global Average Pooling layer\n    x = layers.GlobalAveragePooling2D()(x)\n\n    # Fully connected layers with L2 Regularization\n    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = layers.Dropout(0.5)(x)  # Dropout added to reduce overfitting\n    final_output = layers.Dense(num_classes, activation='sigmoid')(x)\n    \n    model = models.Model(inputs, final_output)\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),  # Using Adam optimizer for smoother convergence\n        loss='binary_crossentropy',  # Use binary cross entropy for binary classification\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# ================== Learning Rate Scheduler ==================#\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr  # Keep the learning rate constant for the first 10 epochs\n    return lr * 0.8  # Reduce learning rate by 20% after 10 epochs\n\ncallback_lr = LearningRateScheduler(scheduler)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"best_model_resnet150.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n\n# ================== Get the Model ==================#\nmodel = create_resnet150(input_shape=(256, 256, 3))\n\n# ================== Train the Model ==================#\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=20,\n    callbacks=[callback_lr, early_stopping, model_checkpoint],\n    verbose=1\n)\n\n# ================== Evaluation ==================#\ntest_loss, test_acc = model.evaluate(test_dataset)\nprint(f\"Test Accuracy: {test_acc * 100:.2f}%\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n\n# ================== Plot Accuracy & Loss ==================#\nplt.figure(figsize=(10, 6))\n\n# Plot training vs validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training vs Validation Accuracy')\nplt.legend()\n\n# Plot training vs validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training vs Validation Loss')\nplt.legend()\n\nplt.show()\n\n# ================== Save Final Model ==================#\nmodel.save('/kaggle/working/resnet150_model.h5')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/resnet150_lung_model.zip /kaggle/working/resnet150_model.h5","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}