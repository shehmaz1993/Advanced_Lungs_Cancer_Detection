{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280},{"sourceId":2882784,"sourceType":"datasetVersion","datasetId":1748489}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n# Clear any existing GPU settings\ntf.keras.backend.clear_session()\n\n# Set TensorFlow to run on GPU\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Allow memory growth to prevent OOM (Out-of-Memory) errors\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"GPU is set up successfully!\")\n    except RuntimeError as e:\n        print(f\"GPU Setup Error: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:22:40.665667Z","iopub.execute_input":"2025-04-08T14:22:40.665982Z","iopub.status.idle":"2025-04-08T14:22:54.199314Z","shell.execute_reply.started":"2025-04-08T14:22:40.665955Z","shell.execute_reply":"2025-04-08T14:22:54.198564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom imblearn.over_sampling import ADASYN\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:22:58.207214Z","iopub.execute_input":"2025-04-08T14:22:58.207763Z","iopub.status.idle":"2025-04-08T14:22:59.368254Z","shell.execute_reply.started":"2025-04-08T14:22:58.207735Z","shell.execute_reply":"2025-04-08T14:22:59.367375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset paths\ndataset1_path = \"/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets\"\ndataset2_path = \"/kaggle/input/iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset\"\n\n# Define target combined dataset path\ncombined_dataset_path = \"/kaggle/working/Combined_Lung_Dataset\"\n\n# Mapping of original dataset folders to new 3-class structure\ndatasets = {\n    \"lung_n\": \"Normal\",\n    \"Normal cases\": \"Normal\",\n    \"Bengin cases\": \"Benign\",\n    \"lung_aca\": \"Malignant\",\n    \"lung_scc\": \"Malignant\",\n    \"Malignant cases\": \"Malignant\",\n}\n\n# Ensure target directories exist\nfor category in set(datasets.values()):\n    os.makedirs(os.path.join(combined_dataset_path, category), exist_ok=True)\n\n# Function to copy images while excluding text files\ndef copy_images(source_folder, target_folder):\n    if os.path.exists(source_folder):\n        for file in os.listdir(source_folder):\n            if file.endswith((\".jpg\", \".png\", \".jpeg\")):  # Copy only image files\n                shutil.copy(os.path.join(source_folder, file), os.path.join(target_folder, file))\n\n# Copy files from dataset 1\nfor folder, category in datasets.items():\n    source_folder = os.path.join(dataset1_path, folder)\n    target_folder = os.path.join(combined_dataset_path, category)\n    copy_images(source_folder, target_folder)\n\n# Copy files from dataset 2\nfor folder, category in datasets.items():\n    source_folder = os.path.join(dataset2_path, folder)\n    target_folder = os.path.join(combined_dataset_path, category)\n    copy_images(source_folder, target_folder)\n\n# Remove empty folders\nfor category in set(datasets.values()):\n    target_folder = os.path.join(combined_dataset_path, category)\n    if len(os.listdir(target_folder)) == 0:  # If the folder is empty\n        print(f\"Removing empty folder: {target_folder}\")\n        shutil.rmtree(target_folder)\n\nprint(\"Dataset successfully merged into 3 classes: Normal, Benign, Malignant!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:23:02.923689Z","iopub.execute_input":"2025-04-08T14:23:02.924236Z","iopub.status.idle":"2025-04-08T14:25:41.954461Z","shell.execute_reply.started":"2025-04-08T14:23:02.924209Z","shell.execute_reply":"2025-04-08T14:25:41.953576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the path to the merged dataset\ncombined_dataset_path = \"/kaggle/working/Combined_Lung_Dataset\"\n\n# Initialize a dictionary to store class-wise image count\nclass_counts = {}\n\n# Loop through each class folder and count images\nfor class_name in os.listdir(combined_dataset_path):\n    class_folder = os.path.join(combined_dataset_path, class_name)\n    if os.path.isdir(class_folder):  # Ensure it's a folder\n        num_images = len([file for file in os.listdir(class_folder) if file.endswith((\".jpg\", \".png\", \".jpeg\"))])\n        class_counts[class_name] = num_images\n\n# Display the result\nfor class_name, count in class_counts.items():\n    print(f\"{class_name}: {count} images\")\n\n# Total images across all classes\ntotal_images = sum(class_counts.values())\nprint(f\"\\nTotal Images: {total_images}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T14:30:13.078832Z","iopub.execute_input":"2025-04-08T14:30:13.079127Z","iopub.status.idle":"2025-04-08T14:30:13.096228Z","shell.execute_reply.started":"2025-04-08T14:30:13.079107Z","shell.execute_reply":"2025-04-08T14:30:13.095411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === IMPORTS ===\nimport os\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport zipfile\nimport random\nimport numpy as np\nfrom torch.autograd import grad\nimport torch.nn.functional as F\nfrom IPython.display import FileLink\n\n# === CONFIG ===\ncombined_dataset_path = \"/kaggle/working/Combined_Lung_Dataset\"\nbenign_dir = os.path.join(combined_dataset_path, \"Benign\")\ndummy_class_dir = os.path.join(benign_dir, \"DummyClass\")\nimage_size = 256\nbatch_size = 32\nlatent_dim = 100\nepochs = 1200\nlr = 1e-4\nn_critic = 5\nlambda_gp = 10\n\ncheckpoint_dir = \"/kaggle/working/checkpoints_benign_gan\"\nsample_dir = \"/kaggle/working/generated_benign\"\nos.makedirs(checkpoint_dir, exist_ok=True)\nos.makedirs(sample_dir, exist_ok=True)\n\noutput_dir = \"/kaggle/working/Synthetic_Benign_Images\"\nos.makedirs(output_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# === FIX FOLDER STRUCTURE ===\nif not os.path.exists(dummy_class_dir):\n    os.makedirs(dummy_class_dir)\n    for file in os.listdir(benign_dir):\n        file_path = os.path.join(benign_dir, file)\n        if os.path.isfile(file_path) and file.lower().endswith(('.jpg', '.jpeg', '.png')):\n            shutil.move(file_path, os.path.join(dummy_class_dir, file))\n\n# === TRANSFORMS ===\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\n# === DATASET ===\ndataset = datasets.ImageFolder(root=benign_dir, transform=transform)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n# === GENERATOR ===\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.ConvTranspose2d(latent_dim, 1024, 4, 1, 0),   # 4x4\n            nn.BatchNorm2d(1024), nn.ReLU(True),\n            nn.ConvTranspose2d(1024, 512, 4, 2, 1),          # 8x8\n            nn.BatchNorm2d(512), nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, 4, 2, 1),           # 16x16\n            nn.BatchNorm2d(256), nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1),           # 32x32\n            nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),            # 64x64\n            nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, 32, 4, 2, 1),             # 128x128\n            nn.BatchNorm2d(32), nn.ReLU(True),\n            nn.ConvTranspose2d(32, 3, 4, 2, 1),              # 256x256\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.model(z)\n\n# === DISCRIMINATOR (CLEAN WITHOUT MINIBATCH DISCRIMINATION) ===\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True)\n        )\n\n        dummy = torch.zeros(1, 3, image_size, image_size)\n        with torch.no_grad():\n            out = self.features(dummy)\n        self.flat_features = out.view(1, -1).shape[1]\n        print(\"[DEBUG] flat_features computed for final layer:\", self.flat_features)\n\n        self.final = nn.Linear(self.flat_features, 1)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        return self.final(x)\n# === GRADIENT PENALTY ===\ndef compute_gradient_penalty(D, real_samples, fake_samples):\n    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n    d_interpolates = D(interpolates)\n    fake = torch.ones_like(d_interpolates, requires_grad=False)\n    gradients = grad(outputs=d_interpolates, inputs=interpolates,\n                     grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n    return gradient_penalty\n\n# === INIT MODELS ===\nnetG = Generator().to(device)\nnetD = Discriminator().to(device)\noptimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.9))\noptimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.9))\n\nfixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n\n# === TRAINING LOOP ===\nfor epoch in range(epochs):\n    for i, (imgs, _) in enumerate(dataloader):\n        real_imgs = imgs.to(device)\n        batch_size = real_imgs.size(0)\n\n        for _ in range(n_critic):\n            z = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n            fake_imgs = netG(z).detach()\n\n            real_validity = netD(real_imgs)\n            fake_validity = netD(fake_imgs)\n            gp = compute_gradient_penalty(netD, real_imgs, fake_imgs)\n            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gp\n\n            optimizer_D.zero_grad()\n            d_loss.backward()\n            optimizer_D.step()\n\n        z = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n        gen_imgs = netG(z)\n        g_loss = -torch.mean(netD(gen_imgs))\n\n        optimizer_G.zero_grad()\n        g_loss.backward()\n        optimizer_G.step()\n\n        if i % 10 == 0:\n            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] Loss_D: {d_loss.item():.4f}, Loss_G: {g_loss.item():.4f}\")\n\n    save_image(netG(fixed_noise).detach().cpu(), os.path.join(sample_dir, f\"epoch_{epoch}.png\"), normalize=True)\n\n    torch.save({\n        'epoch': epoch,\n        'netG': netG.state_dict(),\n        'netD': netD.state_dict(),\n        'optimizerG': optimizer_G.state_dict(),\n        'optimizerD': optimizer_D.state_dict(),\n    }, os.path.join(checkpoint_dir, 'checkpoint.pth'))\n\n    print(f\"\\u2705 Checkpoint saved at epoch {epoch}\")\n\n# === GENERATE FINAL SYNTHETIC IMAGES ===\nnetG.eval()\nnum_generate = 5000\nfor i in range(num_generate):\n    z = torch.randn(1, latent_dim, 1, 1, device=device)\n    with torch.no_grad():\n        img = netG(z).detach().cpu()\n    save_image(img, os.path.join(output_dir, f\"benign_{i:04d}.png\"), normalize=True)\n\nprint(f\"\\u2705 {num_generate} synthetic benign images saved to {output_dir}\")\n\n# === ZIP CHECKPOINTS ===\noutput_zip = \"/kaggle/working/checkpoints_benign_gan.zip\"\nwith zipfile.ZipFile(output_zip, \"w\") as zipf:\n    for root, _, files in os.walk(checkpoint_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, checkpoint_dir)\n            zipf.write(file_path, arcname)\n\nprint(\"\\ud83d\\udce6 Checkpoint zipped at: /kaggle/working/checkpoints_benign_gan.zip\")\n# Define the directory path\nfolder_path = \"/kaggle/working/Synthetic_Benign_Images\"\nzip_path = \"/kaggle/working/Synthetic_Benign_Images.zip\"\n\n# Zip the folder\nshutil.make_archive(base_name=zip_path.replace('.zip', ''), format='zip', root_dir=folder_path)\n\nprint(f\"✅ Folder zipped at: {zip_path}\")\n# Display download link\nFileLink(zip_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n\n# Directory containing synthetic images\ngenerated_dir = \"/kaggle/working/Synthetic_Benign_Images\"\n\n# Pick a few sample image filenames\nsample_files = sorted(os.listdir(generated_dir))[:9]  # First 9 images\n\n# Plot them in a 3x3 grid\nplt.figure(figsize=(10, 10))\nfor i, file in enumerate(sample_files):\n    img_path = os.path.join(generated_dir, file)\n    img = Image.open(img_path)\n\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(img)\n    plt.title(file)\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-08T19:59:13.144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Step 1: Zip the folder\nzip_path = '/kaggle/working/Synthetic_Benign_Images.zip'\nshutil.make_archive(base_name='/kaggle/working/Synthetic_Benign_Images', \n                    format='zip', \n                    root_dir='/kaggle/working/Synthetic_Benign_Images')\n\n# Step 2: Generate a download link\nFileLink(zip_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}